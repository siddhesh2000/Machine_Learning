# -*- coding: utf-8 -*-
"""Credit card fraud detection.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1isG50NA6eAzhHvkuKvFDQxHTVVnBW9Lt

# Part 1: Data preprocessing

Dataset link: https://www.kaggle.com/mlg-ulb/creditcardfraud?select=creditcard.csv

## Importing the libraries and the dataset
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Install kaggle API
! pip install -q kaggle

# upload kaggle API key to colab notebook

# Make directory named kaggle and copy kaggle.json file there
! mkdir ~/.kaggle
! cp kaggle.json ~/.kaggle/

# disable API key
! chmod 600 /root/.kaggle/kaggle.json

# import the dataset
! kaggle datasets download -d mlg-ulb/creditcardfraud

# unzipping the dataset
! unzip -q /content/creditcardfraud.zip

"""## Data Exploration"""

dataset = pd.read_csv('/content/creditcard.csv')

dataset.head()

dataset.shape

dataset.columns

dataset.info()

# statistical summary
dataset.describe()

"""## Dealing with missing values"""

dataset.isnull().values.any()

dataset.isnull().values.sum()

"""## Encoding categorical data"""

dataset.select_dtypes(include='object').columns

len(dataset.select_dtypes(include='object').columns)

"""## Countplot"""

sns.countplot(dataset['Class'])

# non fraud transactions
(dataset.Class == 0).sum()

# fraud transactions
(dataset.Class == 1).sum()

"""## Correlation matrix and heatmap"""

dataset_2 = dataset.drop(columns='Class')

dataset_2.corrwith(dataset['Class']).plot.bar(
    figsize=(16, 9), title='Correlated with Class', grid=True
)

corr = dataset.corr()

plt.figure(figsize=(16, 9))
ax = sns.heatmap(corr, annot=True, linewidths=2)

"""## Splitting the dataset"""

dataset.head()

# matrix of features / independent variables
x = dataset.drop(columns='Class')

# target variable / dependent variable
y = dataset['Class']

from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state=0)

x_train.shape

y_train.shape

x_test.shape

y_test.shape

"""## Feature scaling"""

from sklearn.preprocessing import StandardScaler
sc = StandardScaler()
x_train = sc.fit_transform(x_train)
x_test = sc.transform(x_test)

x_train

x_test

"""# Part 2: Building the model

## 1) Logistic regression
"""

from sklearn.linear_model import LogisticRegression
classifier_lr = LogisticRegression(random_state=0)
classifier_lr.fit(x_train, y_train)

y_pred = classifier_lr.predict(x_test)

from sklearn.metrics import confusion_matrix, accuracy_score

acc = accuracy_score(y_test, y_pred)
print(acc*100)

cm = confusion_matrix(y_test, y_pred)
print(cm)

"""## 2) Random forest"""

from sklearn.ensemble import RandomForestClassifier
classifier_rf = RandomForestClassifier(random_state=0)
classifier_rf.fit(x_train, y_train)

y_pred = classifier_rf.predict(x_test)

from sklearn.metrics import confusion_matrix, accuracy_score
acc = accuracy_score(y_test, y_pred)
print(acc*100)

cm = confusion_matrix(y_test, y_pred)
print(cm)

"""## 3) XGBoost classifier"""

from xgboost import XGBClassifier
classifier_xgb = XGBClassifier(random_state=0)
classifier_xgb.fit(x_train, y_train)

y_pred = classifier_xgb.predict(x_test)

from sklearn.metrics import confusion_matrix, accuracy_score
acc = accuracy_score(y_test, y_pred)
print(acc*100)

cm = confusion_matrix(y_test, y_pred)
print(cm)

"""# Part 3: Final model (Random forest)"""

from sklearn.ensemble import RandomForestClassifier
classifier = RandomForestClassifier(random_state=0)
classifier.fit(x_train, y_train)

y_pred = classifier.predict(x_test)

from sklearn.metrics import confusion_matrix, accuracy_score
acc = accuracy_score(y_test, y_pred)
print(acc*100)

cm = confusion_matrix(y_test, y_pred)
print(cm)

"""# Part 4: Predicting a single observation"""

dataset.head()

dataset.shape

single_obs = [[0.0, -1.359807,	-0.072781,	2.536347,	1.378155,	-0.338321,	0.462388,	0.239599,	0.098698,	0.363787,	0.090794,	-0.551600,	-0.617801,	-0.991390,	-0.311169,	1.468177,	-0.470401,	0.207971,	0.025791,	0.403993,	0.251412,	-0.018307,	0.277838,	-0.110474,	0.066928,	0.128539,	-0.189115,	0.133558,	-0.021053,	149.62
]]

classifier.predict(sc.transform(single_obs))