# -*- coding: utf-8 -*-
"""Used car price prediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1tjoFbqURjtc06DCrcCkIxFsuxzZbr9M7

# Part 1: Data preprocessing

Dataset link: https://www.kaggle.com/nehalbirla/vehicle-dataset-from-cardekho?select=car+data.csv

## Importing the libraries and the dataset
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

dataset = pd.read_csv('/content/car data.csv')

dataset.head()

"""## Data exploration"""

dataset.shape

dataset.columns

dataset.info()

# categorical columns
dataset.select_dtypes(include='object').columns

len(dataset.select_dtypes(include='object').columns)

# numerical columns
dataset.select_dtypes(include=['float64', 'int64']).columns

len(dataset.select_dtypes(include=['float64', 'int64']).columns)

dataset.describe()

"""## Dealing with missing values"""

dataset.isnull().values.any()

dataset.isnull().values.sum()

"""## Restructure the dataset"""

dataset.head()

dataset = dataset.drop(columns='Car_Name')

dataset.head()

# add a column
dataset['Current Year'] = 2020

dataset.head()

dataset['Years Old'] = dataset['Current Year'] - dataset['Year']

dataset.head()

dataset = dataset.drop(columns=['Current Year', 'Year'])

dataset.head()

"""## Encoding the categorical data"""

dataset.select_dtypes(include='object').columns

len(dataset.select_dtypes(include='object').columns)

dataset['Fuel_Type'].nunique()

dataset['Seller_Type'].nunique()

dataset['Transmission'].nunique()

dataset.shape

# one hot encoding
dataset = pd.get_dummies(data=dataset, drop_first=True)

dataset.head()

dataset.shape

"""## Correlation matrix"""

dataset_2 = dataset.drop(columns='Selling_Price')

dataset_2.corrwith(dataset['Selling_Price']).plot.bar(
    figsize=(16,9), title='Correlated with Selling Price', grid=True
)

corr = dataset.corr()

# heatmap
plt.figure(figsize=(16, 9))
sns.heatmap(corr, annot=True)

"""## Splitting the dataset"""

dataset.head()

# matrix of features
x = dataset.drop(columns='Selling_Price')

# target variable
y = dataset['Selling_Price']

from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=0)

x_train.shape

y_train.shape

x_test.shape

y_test.shape

"""## Feature scaling"""

# we are not applying the feature scaling for this specific business problem

"""# Part 2: Building the model

## 1) Multiple linear regression
"""

from sklearn.linear_model import LinearRegression
regressor_mlr = LinearRegression()
regressor_mlr.fit(x_train, y_train)

y_pred = regressor_mlr.predict(x_test)

from sklearn.metrics import r2_score

r2_score(y_test, y_pred)

"""## 2) Random forest regression"""

from sklearn.ensemble import RandomForestRegressor
regressor_rf = RandomForestRegressor()
regressor_rf.fit(x_train, y_train)

y_pred = regressor_rf.predict(x_test)

from sklearn.metrics import r2_score
r2_score(y_test, y_pred)

"""# Part 3: Fing the optimal parameters using RandomizedSearchCV"""

from sklearn.model_selection import RandomizedSearchCV

parameters = {
    'n_estimators':[100, 200, 300, 400, 500, 600, 700, 800, 900, 1000],
    'criterion':['mse', 'mae'],
    'max_depth':[10, 20, 30, 40, 50],
    'min_samples_split':[2, 5, 10, 20, 50],
    'min_samples_leaf':[1, 2, 5, 10],
    'max_features':['auto', 'sqrt', 'log2']
}

parameters

random_cv = RandomizedSearchCV(estimator=regressor_rf, param_distributions=parameters, n_iter=10,
                               scoring='neg_mean_absolute_error', cv=5, verbose=2, n_jobs=-1)

random_cv.fit(x_train, y_train)

random_cv.best_estimator_

random_cv.best_params_

"""# Part 4: Final model (Random forest)"""

from sklearn.ensemble import RandomForestRegressor
regressor = RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',
                      max_depth=None, max_features='auto', max_leaf_nodes=None,
                      max_samples=None, min_impurity_decrease=0.0,
                      min_impurity_split=None, min_samples_leaf=1,
                      min_samples_split=2, min_weight_fraction_leaf=0.0,
                      n_estimators=100, n_jobs=None, oob_score=False,
                      random_state=None, verbose=0, warm_start=False)
regressor.fit(x_train, y_train)

y_pred = regressor.predict(x_test)

from sklearn.metrics import r2_score
r2_score(y_test, y_pred)

"""# Part 5: Predicting a single observation"""

dataset.head()

single_obs = [[8.50, 3500, 0, 5, 1, 0, 0, 1]]

regressor.predict(single_obs)